import torch
import torchaudio
import torch.nn.functional as F
from nemo.collections.asr.models import EncDecSpeakerLabelModel
from sklearn.cluster import KMeans

# ===== LOAD MODELS =====
print("ğŸ”„ Loading models...")
titanet = EncDecSpeakerLabelModel.from_pretrained("titanet_small")

# Load Silero VAD
model, utils = torch.hub.load(
    repo_or_dir='snakers4/silero-vad',
    model='silero_vad',
    force_reload=True,
    onnx=False
)
(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils

# ===== HÃ€M VAD TÃCH ÄOáº N SPEECH =====
def get_speech_segments(wav, sr):
    wav = wav.squeeze()  # [1, N] -> [N]
    speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sr)
    return speech_timestamps

# ===== HÃ€M Láº¤Y EMBEDDING =====
def extract_embedding(segment_wav, sr):
    if sr != 16000:
        segment_wav = torchaudio.functional.resample(segment_wav, sr, 16000)
        sr = 16000
    emb = titanet.get_embedding(segment_wav.unsqueeze(0), sr)  # thÃªm batch dim
    return emb.squeeze().cpu().numpy()

# ===== MAIN =====
file = "conversation-test.wav"
wav, sr = torchaudio.load(file)

# Náº¿u stereo -> láº¥y 1 kÃªnh
if wav.shape[0] > 1:
    wav = wav[0:1, :]

# ğŸ”¥ Resample vá» 16kHz
if sr != 16000:
    wav = torchaudio.functional.resample(wav, sr, 16000)
    sr = 16000

# Láº¥y cÃ¡c Ä‘oáº¡n cÃ³ speech báº±ng VAD
segments = get_speech_segments(wav, sr)

embeddings = []
segment_infos = []

for seg in segments:
    start = int(seg['start'] * sr)
    end   = int(seg['end'] * sr)
    segment_wav = wav[:, start:end]

    # Bá» Ä‘oáº¡n quÃ¡ ngáº¯n < 0.25s
    if segment_wav.shape[1] < sr * 0.1:
        continue

    emb = extract_embedding(segment_wav, sr)
    embeddings.append(emb)
    segment_infos.append((seg['start'], seg['end']))

# ===== KIá»‚M TRA VÃ€ CLUSTER =====
if len(embeddings) < 2:
    print("âš ï¸ KhÃ´ng Ä‘á»§ Ä‘oáº¡n Ä‘á»ƒ phÃ¢n biá»‡t ngÆ°á»i nÃ³i (file quÃ¡ ngáº¯n hoáº·c VAD khÃ´ng phÃ¡t hiá»‡n).")
else:
    kmeans = KMeans(n_clusters=2, random_state=0).fit(embeddings)
    labels = kmeans.labels_

    print("\n===== Káº¾T QUáº¢ PHÃ‚N LOáº I SPEAKER =====")
    for i, (start, end) in enumerate(segment_infos):
        print(f"Äoáº¡n {i+1}: {start:.2f}s â€“ {end:.2f}s --> Speaker {labels[i]}")
